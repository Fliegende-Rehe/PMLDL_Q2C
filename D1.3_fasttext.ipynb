{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Workspace"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import torch\n",
    "import fasttext\n",
    "import argparse\n",
    "import fasttext.util\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import GloVe\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "STOP_WORDS = stopwords.words('english')\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "GLOVE = GloVe(name=\"6B\", dim=50)\n",
    "COS = torch.nn.CosineSimilarity(dim=0)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "RANDOM_SEED = 420\n",
    "\n",
    "MAX_EPOCHS = 15\n",
    "VEC_SIZE = 300\n",
    "ALPHA = 0.025\n",
    "BATCH_SIZE = 512\n",
    "MAX_WORDS = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "df = None\n",
    "try:\n",
    "    %store -r df\n",
    "except KeyError:\n",
    "    df = pd.read_csv('formated_dataframe.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Selection [Word Embeddings]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T10:45:18.092365Z",
     "iopub.status.busy": "2023-10-08T10:45:18.092030Z",
     "iopub.status.idle": "2023-10-08T10:45:18.411160Z",
     "shell.execute_reply": "2023-10-08T10:45:18.410163Z",
     "shell.execute_reply.started": "2023-10-08T10:45:18.092337Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.drop(columns=['id', 'qid1', 'qid2', 'questions_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T10:45:19.375517Z",
     "iopub.status.busy": "2023-10-08T10:45:19.375185Z",
     "iopub.status.idle": "2023-10-08T10:45:19.909677Z",
     "shell.execute_reply": "2023-10-08T10:45:19.908690Z",
     "shell.execute_reply.started": "2023-10-08T10:45:19.375490Z"
    }
   },
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(data, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "train, val = train_test_split(train_val, test_size=VAL_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T11:06:46.051006Z",
     "iopub.status.busy": "2023-10-08T11:06:46.050626Z",
     "iopub.status.idle": "2023-10-08T11:06:46.058602Z",
     "shell.execute_reply": "2023-10-08T11:06:46.057632Z",
     "shell.execute_reply.started": "2023-10-08T11:06:46.050978Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_collate_batch_fn(emb_func):\n",
    "    def f(batch):\n",
    "        label_list = []\n",
    "        embeddings_tensor = torch.zeros(len(batch), 2, max_words, embed_len)\n",
    "        for i, data in enumerate(batch):\n",
    "            q1, q2, label, q1_length, q2_length, q1_special_chars, q2_special_chars, q1_stopwords, \\\n",
    "                q2_stopwords, common_words, common_words_count, q1_preprocessed, q2_preprocessed, q1_ngrams, q2_ngrams = data\n",
    "\n",
    "            if len(q1_preprocessed) < max_words:\n",
    "                q1_preprocessed += [\"\"] * (max_words - len(q1_preprocessed))\n",
    "            else:\n",
    "                q1_preprocessed = q1_preprocessed[:max_words]\n",
    "\n",
    "            if len(q2_preprocessed) < max_words:\n",
    "                q2_preprocessed += [\"\"] * (max_words - len(q2_preprocessed))\n",
    "            else:\n",
    "                q2_preprocessed = q2_preprocessed[:max_words]\n",
    "\n",
    "            label_list.append(int(label))\n",
    "            embeddings_tensor[i, 0] = emb_func(q1_preprocessed)\n",
    "            embeddings_tensor[i, 1] = emb_func(q2_preprocessed)\n",
    "        label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "        return embeddings_tensor.reshape(len(batch), 2, -1).to(DEVICE), label_list.to(DEVICE)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collate_batch_fn_compare(emb_func):\n",
    "    def f(batch):\n",
    "        embeddings_tensor = torch.zeros(len(batch) * 2, max_words, embed_len)\n",
    "        counter = 0\n",
    "        for i, data in enumerate(batch):\n",
    "            q1, q2, label, q1_length, q2_length, q1_special_chars, q2_special_chars, q1_stopwords, \\\n",
    "                q2_stopwords, common_words, common_words_count, q1_preprocessed, q2_preprocessed, q1_ngrams, q2_ngrams = data\n",
    "\n",
    "            if len(q1_preprocessed) < max_words:\n",
    "                q1_preprocessed += [\"\"] * (max_words - len(q1_preprocessed))\n",
    "            else:\n",
    "                q1_preprocessed = q1_preprocessed[:max_words]\n",
    "\n",
    "            if len(q2_preprocessed) < max_words:\n",
    "                q2_preprocessed += [\"\"] * (max_words - len(q2_preprocessed))\n",
    "            else:\n",
    "                q2_preprocessed = q2_preprocessed[:max_words]\n",
    "            embeddings_tensor[counter] = emb_func(q1_preprocessed)\n",
    "            counter += 1\n",
    "            embeddings_tensor[counter] = emb_func(q2_preprocessed)\n",
    "            counter += 1\n",
    "        return embeddings_tensor.to(DEVICE)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_emb(emb_func):\n",
    "    def f(prep):\n",
    "        if len(prep) < max_words:\n",
    "            prep += [\"\"] * (max_words - len(prep))\n",
    "        else:\n",
    "            prep = prep[:max_words]\n",
    "\n",
    "        return emb_func(prep).to(DEVICE)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most similar question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(q1, q2):\n",
    "    return COS(q1.reshape(-1), q2.reshape(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_single_str(s):\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    s = re.sub(r'[0-9]+', '', s)\n",
    "    s = word_tokenize(s)\n",
    "    s = [word.lower() for word in s]\n",
    "    s = [word for word in s if word not in (stop)]\n",
    "    s = [lemmatizer.lemmatize(word) for word in s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_from_batch_index(index):\n",
    "    col = index % 2\n",
    "    row = index // 2\n",
    "    if col == 0:\n",
    "        return data.iloc[row][\"question1\"]\n",
    "    return data.iloc[row][\"question2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_question(user_request):\n",
    "    user_request_preprocessed = preprocess_single_str(user_request)\n",
    "    user_emb = single_emb(user_request_preprocessed)\n",
    "\n",
    "    max_score = None\n",
    "    best_index = None\n",
    "    counter = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        for emb in batch:\n",
    "            cos_sim = cosine_similarity(emb, user_emb)\n",
    "            if max_score is None or cos_sim > max_score:\n",
    "                max_score = cos_sim\n",
    "                best_index = counter\n",
    "            counter += 1\n",
    "\n",
    "    return get_q_from_batch_index(best_index), max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embedding(q):\n",
    "    return GLOVE.get_vecs_by_tokens(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_batch = create_collate_batch_fn_compare(get_glove_embedding)\n",
    "single_emb = create_single_emb(get_glove_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T11:06:47.252583Z",
     "iopub.status.busy": "2023-10-08T11:06:47.252242Z",
     "iopub.status.idle": "2023-10-08T11:06:47.420799Z",
     "shell.execute_reply": "2023-10-08T11:06:47.419649Z",
     "shell.execute_reply.started": "2023-10-08T11:06:47.252556Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    data.to_numpy(), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4c9cc86d51481bb0f0c587ce585658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Does he want to go out with me?', 0.8569372296333313)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_question(\"Do you want to go to a bar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Why do you love her?', 0.9999998807907104)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_question(\"Do you love me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_similar_question(\"How much money do you have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below allows to download pretrained fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_download(lang_id, if_exists):\n",
    "    \"\"\"\n",
    "        Download pre-trained common-crawl vectors from fastText's website\n",
    "        https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "    \"\"\"\n",
    "    fasttext.util.download_model(lang_id, if_exists)\n",
    "\n",
    "\n",
    "from IPython.utils import io\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    command_download(\"en\", if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = fasttext.load_model(\"cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_embedding(q):\n",
    "    return torch.Tensor(fasttext_model.get_sentence_vector(\" \".join(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    embeddings_tensor = torch.zeros(len(batch) * 2, max_words)\n",
    "    counter = 0\n",
    "    for i, data in enumerate(batch):\n",
    "        q1, q2, label, q1_length, q2_length, q1_special_chars, q2_special_chars, q1_stopwords, \\\n",
    "            q2_stopwords, common_words, common_words_count, q1_preprocessed, q2_preprocessed, q1_ngrams, q2_ngrams = data\n",
    "\n",
    "        if len(q1_preprocessed) < max_words:\n",
    "            q1_preprocessed += [\"\"] * (max_words - len(q1_preprocessed))\n",
    "        else:\n",
    "            q1_preprocessed = q1_preprocessed[:max_words]\n",
    "\n",
    "        if len(q2_preprocessed) < max_words:\n",
    "            q2_preprocessed += [\"\"] * (max_words - len(q2_preprocessed))\n",
    "        else:\n",
    "            q2_preprocessed = q2_preprocessed[:max_words]\n",
    "        embeddings_tensor[counter] = get_fasttext_embedding(q1_preprocessed)\n",
    "        counter += 1\n",
    "        embeddings_tensor[counter] = get_fasttext_embedding(q2_preprocessed)\n",
    "        counter += 1\n",
    "    return embeddings_tensor.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_emb = create_single_emb(get_fasttext_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    data.to_numpy(), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3cd619ccb04f7a8634053c47ad8b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Does he want to go out with me?', 0.8843696117401123)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_question(\"Do you want to go to a bar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b59b8cfd2cb4fbf87bbd5bcd86f4067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Why do you love her?', 0.9999998807907104)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_question(\"Do you love me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    l = []\n",
    "    for i, data in enumerate(batch):\n",
    "        q1, q2, label, q1_length, q2_length, q1_special_chars, q2_special_chars, q1_stopwords, \\\n",
    "            q2_stopwords, common_words, common_words_count, q1_preprocessed, q2_preprocessed, q1_ngrams, q2_ngrams = data\n",
    "        l.append(list(filter(lambda a: a != '', q1_preprocessed)))\n",
    "        l.append(list(filter(lambda a: a != '', q2_preprocessed)))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013eaa3b28414cec864860f020222cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    data.to_numpy(), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "counter = 0\n",
    "for batch in tqdm(dataloader):\n",
    "    for emb in batch:\n",
    "        t = TaggedDocument(words=emb, tags=[str(counter)])\n",
    "        tagged_data.append(t)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec(\n",
    "    vector_size=VEC_SIZE,\n",
    "    alpha=ALPHA,\n",
    "    min_alpha=0.00025,\n",
    "    min_count=1,\n",
    "    dm=1\n",
    ")\n",
    "\n",
    "doc2vec.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(MAX_EPOCHS):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    doc2vec.train(\n",
    "        tagged_data,\n",
    "        total_examples=model.corpus_count,\n",
    "        epochs=1\n",
    "    )\n",
    "    # decrease the learning rate\n",
    "    doc2vec.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    doc2vec.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc2vec_embedding(q):\n",
    "    result = torch.Tensor(doc2vec.infer_vector(q))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 300\n",
    "embed_len = max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_emb = get_doc2vec_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    embeddings_tensor = torch.zeros(len(batch) * 2, max_words)\n",
    "    counter = 0\n",
    "    for i, data in enumerate(batch):\n",
    "        q1, q2, label, q1_length, q2_length, q1_special_chars, q2_special_chars, q1_stopwords, \\\n",
    "            q2_stopwords, common_words, common_words_count, q1_preprocessed, q2_preprocessed, q1_ngrams, q2_ngrams = data\n",
    "\n",
    "        embeddings_tensor[counter] = get_doc2vec_embedding(q1_preprocessed)\n",
    "        counter += 1\n",
    "        embeddings_tensor[counter] = get_doc2vec_embedding(q2_preprocessed)\n",
    "        counter += 1\n",
    "    return embeddings_tensor.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    data.to_numpy(), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77f15977e33408dbdca092873fb3cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Which TMT bars are best for construction of residential houses in India? And why? Which brand name is preferred over the other?',\n",
       " 0.7966447472572327)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_question(\"Do you want to go to a bar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984848b56e23411fb20661489877410b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Why should you love yourself?', 0.82894366979599)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar_question(\"Do you love me?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
